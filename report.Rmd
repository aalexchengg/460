
---
title: "36-460/660 Final Project Report"
author: "Alex Cheng, Melody Wang, Liz Chu, Kevin Ren"
date: "April 23rd, 2024"
output:
  pdf_document:
    toc: yes
  html_document:
    code_folding: show
    toc: yes
    toc_float: yes
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library("nflfastR")
library(espnscrapeR)
library("ggplot2")
library(tidyverse)
library(dplyr)
library(lme4)
library(mgcv)
library(nnet)
df <- read_csv("runrunrun.csv")
df$outcome = ifelse(df$play_type == "run", 1, 0) 
# 1 if run, 0 otherwise (pass)
success_df = df %>% filter(success == 1)
```

```{r models}

model1 <- glm(outcome ~ as.factor(prev_play_1) + as.factor(prev_play_2) + 
                as.factor(prev_play_3) + ydstogo + score_differential + 
                pass_rank + rush_rank, data=success_df, family="binomial")
model2 <- gam(outcome ~ as.factor(prev_play_1) + as.factor(prev_play_2) + 
                as.factor(prev_play_3) + s(ydstogo) + s(score_differential) + 
                pass_rank + rush_rank, data=success_df, family="binomial")
model4 <- glmer(outcome ~ as.factor(prev_play_1) + as.factor(prev_play_2) + 
                  as.factor(prev_play_3) + (1|posteam) + (1|defteam) + 
                  (1|posteam:defteam) + ydstogo + pass_rank, 
                data = success_df, family = "binomial")
# filtering for model 3
filt_df = success_df %>% filter((play_type == "pass" & !is.na(pass_length) & 
                      !is.na(pass_location)) | 
                     (play_type == "run" & !is.na(run_location)))
filt_df$multi = ifelse(filt_df$play_type == "run", paste("run", filt_df$run_location), 
                  paste("pass", filt_df$pass_length, filt_df$pass_location))

model3 <- multinom(multi ~ as.factor(prev_play_1) + as.factor(prev_play_2) + 
                     as.factor(prev_play_3) + ydstogo + score_differential + 
                     pass_rank + rush_rank, data = filt_df, maxit = 300, 
                   trace = FALSE)

# use success_df for only successful plays, 
# filt_df for successful plays specifically for model 3
```

# Introduction

The problem of playcalling is among the greatest challenges in sports coaching, particularly in the sport of American football. Particularly poor calls -- e.g. the Seahawk's decision to pass rather than run with 1 yard to go in the closing seconds of Super Bowl XLIX -- represent snap decisions that can cause franchises and players alike to lose critical games and ultimately millions of dollars. As such, in order to avoid such outcomes coaches must be very smart about what kinds of plays to run in different scenarios, depending on the previous plays that they have called along with the context of the game. In this project we hope to answer the age-old question of what plays a football coach should call, given the types of the previous three plays in the drive, along with contextual information about the field position such as yards-to-go until a touchdown, the strength of the offensive team in terms of their passing and rushing abilities, and the difference in score in the game. We ultimately find that our fitted models on the given covariates perform strongly on both in-distribution and out-of-distribution data on their respective predictive tasks, compared to a naive baseline model.

# Data

*Describes the data you’re using in detail, where you accessed it, along with relevant exploratory data analysis (EDA). You should also include descriptions of any major pre-processing steps.*

**TODO: we should probably include the code that got us runrunrun.csv somewhere in our code submission**

# Methods

*Describes the modeling techniques you chose, their assumptions, justifications for why they are appropriate for the problem, and your plan for comparison/evaluation approaches. Additionally, you will need to describe how you will quantify uncertainty for your estimates of interest, with sufficient descriptions of the approach and justification for why it’s appropriate for your data and problem of interest.*

# Results

*Describes your results. This can include tables and plots showing your results, as well as text describing how your models worked and the appropriate interpretations of the relevant output. I do not want to you to write out the textbook interpretations of all model coefficients! I only want you to interpret the output that is relevant for your question of interest that is framed in the introduction.*



# Discussion

Overall it was very interesting to see how similarly our chosen models performed given the breadth of the features we chose. This may suggest that our features were not distinct enough from each other or we did not select enough features. This could be plausible as play-calling is a clearly complex process representing the battle between offensive and defensive coaching minds along with the players on the field, not to mention the field position of the play itself. As such, it is plausible that one limitation of our approach is simply that we did not perform enough vetting of the features we chose. In the future we could potentially add more features such as the ranking of the defensive team on the field versus the pass or the run (currently no defensive statistics are considered, which could be troublesome) as well as including features such as which team is home versus away, or perhaps tuning our models on different number of prior plays that the model is able to see.

Secondly, the question of what our training data should look like was something that we could potentially change in the future as well. By nature our data fails to reveal counterfactual outcomes, e.g. the offensive team induces a treatment in the form of a play call, causing some outcome in the form of yards gained, which doesn't allow for seeing what *would* have happened should a different play have been run. As a result we chose not to include what we determined to be 'failed' plays in our training process, and so we modeled the probability that a given play occurred given that it was successful. This process therefore wastes lots of data: no information from the failed plays is reflected in our trained models. Expanding our analysis to be a causal inference question in which we attempt to do some modeling on what play calls could potentially reverse or alter the outcomes of failed plays could represent an interesting statistical question under which future research could be conducted.
